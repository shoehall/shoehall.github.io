---
title: GLM综述
date: 2019-04-08 14:12:26
tags:
---
GLM综述
总纲
GMM（可以认为包括OLS、Logistic、Probit、Poisson等回归）提纲挈领的说就是：
训练一种线性投影使得lambda投影到delta(labmda)。这里的线性是指内积 是线性的，广义是指加入了激活函数 ，调和模型中 与 的差异。另外这里本身加入了x可能到更高维向量空间的映射 。我们的目的就是训练这种映射，获取 值使得， 与 尽可能接近。一般的我们选定 为一个单调递增函数（递减也可以， 调整符号就可以了，只是理解比较麻烦），那么从趋势上可以这样理解——训练 使得，在 给定的情况下， 越大时 越大， 越小时 越小，使得 与 尽可能接近。
示例
基于总纲，我们可以重新审视一下各个模型：
1.	OLS
 
2.	Logit回归
 
3.	Probit回归
 
4.	Gumbel回归（loglog）
 
5.	互补loglog回归
 
上述激活函数的阐述
根据总纲，激活函数 是调和 与 的模式差异的，使之与模型更加接近。
因此：
1.	当 的至于范围 等于 的值域范围，那就不需要调和，只需训练好 那一定能找到有效的模型使得 与 尽可能接近。比如OLS中，y服从正态分布，我们是对正态分布的期望建模， 可能的取值范围为 等于R，恰好等于 的可能取值范围，因此激活函数 。
2.	相反， 的至于范围 于 的值域范围不相当时，需要激活函数调节。比如，y服从伯努利分布时，我们对p建模（如果还对y建模，y只取两个值严重小于 ，说明很多信息没有捕捉到），由于p的值域为（0, 1）因此我们建立0-1的映射。可能的映射为“示例”中的2-5.下面分别分析2-5映射的适用场景。
3.	对比图
4.	Sigmoid激活
Sigmoid两端对称，适合对于
5.	正态累计分布激活
6.	Loglog激活
7.	互补loglog激活
激活函数对最优化的影响

### 原始的work文档
/workplace/studio/papers/glm/GLM综述.docx

